# generate_evolution_graphs.py

import os
import glob
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
import seaborn as sns
import sys
import numpy as np
sys.setrecursionlimit(10000)

# --- Importar módulos desenvolvidos anteriormente ---
try:
    from chunk_transition_analyzer import (
        parse_rules_history_to_asts,
        analyze_chunk_transition, # Esta função agora deve retornar RIR, AMS, TCS
        collect_ast_quantitatives
    )
except ImportError as e:
    print(f"Import Error: {e}")
    print("Please ensure 'chunk_transition_analyzer.py' and its dependencies are accessible.")
    exit()

# --- Configurações Globais ---
MAIN_OUTPUT_FOLDER_NAME = "experiment_results_big_figTransitions"
HISTORY_FILE_PATTERN = "RulesHistory_*.txt"
RUN_FOLDER_NAME = "run_1"

# Limiares para a função analyze_chunk_transition
# Estes valores são passados para analyze_chunk_transition
LEVENSHTEIN_SIMILARITY_PRE_FILTER_CONFIG = 0.5  # Minimum Levenshtein similarity for a pair to be a candidate
SM_THRESHOLD_FOR_MODIFIED_CONFIG = 0.8       # Maximum detailed SM for a candidate pair to be confirmed as modified (SM < threshold)

# def find_experiment_folders(root_path):
#     """
#     Finds subdirectories in the root_path that start with an uppercase letter
#     and contain '_' in their name.
#     These are considered experiment folders.
#     """
#     experiment_folders = []
#     if not os.path.isdir(root_path):
#         print(f"Error: Root path '{root_path}' is not a valid directory.")
#         return experiment_folders

#     # Folders to ignore (previously generated output or other non-experiment folders)
#     folders_to_ignore = {
#         MAIN_OUTPUT_FOLDER_NAME,
#         "composite_mosaics_final", # From the other orchestrator script
#         "global_mosaics_output_paginated", # From the paginated mosaic script
#         "mosaics_output", # From older mosaic scripts
#         "global_mosaics_output" # From older global mosaic scripts
#     }

#     for item in os.listdir(root_path):
#         item_path = os.path.join(root_path, item)
#         if os.path.isdir(item_path) and \
#            item[0].isupper() and \
#            '_' in item and \
#            item not in folders_to_ignore:
#             experiment_folders.append(item_path)
#     return experiment_folders
def find_experiment_folders(root_path_experiments): # Renomeado o parâmetro para clareza
    """
    Finds all subdirectories in the root_path_experiments,
    optionally ignoring specified folders. These are considered experiment folders
    each containing a 'run_1' subfolder with a RulesHistory file.
    """
    experiment_folders = []
    # Folders to ignore (output folders generated by this or other analysis scripts)
    # MAIN_OUTPUT_FOLDER_NAME é o diretório onde este script SALVARÁ os gráficos,
    # então não devemos tentar LER dele como uma pasta de experimento.
    folders_to_ignore = {
        MAIN_OUTPUT_FOLDER_NAME, # Pasta de saída deste próprio script
        "composite_mosaics_final",
        "global_mosaics_output_paginated",
        "mosaics_output",
        "global_mosaics_output"
    }

    if not os.path.isdir(root_path_experiments):
        print(f"Error: Experiment root path '{root_path_experiments}' is not a valid directory.")
        return experiment_folders

    for item in os.listdir(root_path_experiments):
        item_path = os.path.join(root_path_experiments, item)
        # Agora verifica apenas se é um diretório e se não está na lista de ignorados
        if os.path.isdir(item_path) and item not in folders_to_ignore:
            experiment_folders.append(item_path)
    return experiment_folders

def find_history_file(experiment_folder_path):
    """
    Finds the RulesHistory_*.txt file within the 'run_1' subfolder
    of a given experiment folder.
    """
    run_1_path = os.path.join(experiment_folder_path, RUN_FOLDER_NAME)
    if not os.path.isdir(run_1_path):
        return None

    search_pattern = os.path.join(run_1_path, HISTORY_FILE_PATTERN)
    history_files_found = glob.glob(search_pattern)

    if not history_files_found:
        return None
    
    if len(history_files_found) > 1:
        print(f"  Warning: Multiple history files found in '{run_1_path}'. Using the first one: {history_files_found[0]}")
    
    return history_files_found[0]


def plot_evolution_data(df_transitions, output_image_path, plot_title_prefix):
    """
    Generates and saves a multi-panel plot visualizing rule evolution metrics.
    All labels and titles are in English.
    """
    if df_transitions.empty:
        print(f"  No transition data to plot for {plot_title_prefix}.")
        return

    num_transitions = len(df_transitions)
    if num_transitions == 0: return

    if 'transition' not in df_transitions.columns:
        print("  Error: 'transition' column missing in DataFrame for plotting.")
        return
    
    # Usar a coluna 'transition' como rótulos do eixo x diretamente
    x_labels = df_transitions['transition']
    x_ticks = range(num_transitions)


    fig, axes = plt.subplots(3, 1, figsize=(max(12, num_transitions * 1.5), 18), sharex=True)
    fig.suptitle(f"{plot_title_prefix} - Rule Set Evolution Analysis", fontsize=16, y=0.99)
    
    # --- Plot 1: Severity and Instability Metrics ---
    ax1 = axes[0]
    ax1.plot(x_ticks, df_transitions['TCS'], marker='o', linestyle='-', label='TCS (Transition Change Score)', color='red', linewidth=2)
    ax1.plot(x_ticks, df_transitions['RIR'], marker='s', linestyle='--', label='RIR (Rule Instability Rate)', color='blue')
    ax1.plot(x_ticks, df_transitions['AMS'], marker='^', linestyle=':', label='AMS (Average Modification Severity)', color='green')
    ax1.set_ylabel("Score (0-1)")
    ax1.set_title("Transition Severity and Instability Metrics")
    ax1.legend(loc='best') # Ajustado para 'best'
    ax1.grid(True, linestyle='--', alpha=0.7)
    ax1.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.2f'))
    ax1.set_ylim(0, 1.05) # Garante que o eixo Y vá de 0 a 1 (ou um pouco mais)

    # --- Plot 2: Rule Counts ---
    ax2 = axes[1]
    
    # Número de categorias de barras por transição
    num_bar_categories = 4 # Unchanged, Modified, New, Deleted
    
    # Largura de cada barra individual
    bar_width = 0.18 # Pode ajustar este valor
    
    # Espaçamento total para as barras de uma transição + pequeno espaço entre grupos
    group_width = num_bar_categories * bar_width + bar_width # Adiciona um bar_width extra para espaçamento
    
    # Posições X para os centros dos grupos de barras
    x_group_centers = np.arange(num_transitions) * group_width 

    # Plotando as barras com deslocamentos relativos ao centro do grupo
    ax2.bar(x_group_centers - 1.5*bar_width, df_transitions['unchanged'], bar_width, label='Unchanged')
    ax2.bar(x_group_centers - 0.5*bar_width, df_transitions['modified'], bar_width, label='Modified')
    ax2.bar(x_group_centers + 0.5*bar_width, df_transitions['new'], bar_width, label='New (in target chunk)')
    ax2.bar(x_group_centers + 1.5*bar_width, df_transitions['deleted'], bar_width, label='Deleted (from source chunk)')
    
    ax2_twin = ax2.twinx()
    # Para a linha, plotamos usando os mesmos centros dos grupos para alinhamento
    line_total = ax2_twin.plot(x_group_centers, df_transitions['total_rules_j'], marker='x', linestyle='-.', label='Total Rules (in target chunk)', color='purple', linewidth=2)
    
    ax2.set_ylabel("Rule Count")
    ax2_twin.set_ylabel("Total Rules in Target Chunk")
    ax2.set_title("Rule Counts per Transition")
    
    # Ajustar os ticks e rótulos do eixo X para os centros dos grupos
    ax2.set_xticks(x_group_centers) # Define os ticks nos centros dos grupos
    ax2.set_xticklabels(x_labels, rotation=45, ha="right") # x_labels são os nomes das transições

    # ... (legendas e grids como antes) ...
    handles1, labels1_ax2 = ax2.get_legend_handles_labels() # Renomeado para evitar conflito de labels
    handles2, labels2_ax2_twin = ax2_twin.get_legend_handles_labels() # Renomeado
    ax2.legend(handles1 + handles2, labels1_ax2 + labels2_ax2_twin, loc='best')
    ax2.grid(True, linestyle='--', alpha=0.7, axis='y')
    ax2_twin.grid(False)

    # --- Plot 3: Rule Complexity Metrics (for Target Chunk J) ---
    ax3 = axes[2]
    ax3.plot(x_ticks, df_transitions['ands_j'], marker='o', linestyle='-', label='AND Operators')
    ax3.plot(x_ticks, df_transitions['ors_j'], marker='s', linestyle='-', label='OR Operators')
    ax3.plot(x_ticks, df_transitions['atomics_j'], marker='^', linestyle='-', label='Atomic Conditions')
    
    ax3_twin = ax3.twinx()
    ax3_twin.plot(x_ticks, df_transitions['avg_thresh_j'], marker='x', linestyle='--', label='Avg. Threshold Value', color='brown')

    ax3.set_ylabel("Count")
    ax3_twin.set_ylabel("Average Threshold Value")
    ax3.set_title("Rule Complexity Metrics for Target Chunk")
    ax3.legend(loc='best') # Ajustado para 'best'
    ax3_twin.legend(loc='center right') # Ajustado para melhor posicionamento
    ax3.grid(True, linestyle='--', alpha=0.7)
    ax3_twin.grid(False)
    
    # Configurações comuns para o eixo X
    plt.xlabel("Chunk Transition")
    for ax in axes:
        ax.set_xticks(x_ticks)
        ax.set_xticklabels(x_labels, rotation=45, ha="right")
        # Garante que todos os ticks sejam mostrados se houver poucos
        if num_transitions < 10: # Ajuste este valor conforme necessário
            ax.xaxis.set_major_locator(mticker.FixedLocator(x_ticks))


    plt.tight_layout(rect=[0, 0, 1, 0.97]) # Ajustado rect para o suptitle
    
    try:
        os.makedirs(os.path.dirname(output_image_path), exist_ok=True)
        plt.savefig(output_image_path, bbox_inches='tight')
        print(f"  Evolution graph saved to: {output_image_path}")
    except Exception as e:
        print(f"  Error saving evolution graph '{output_image_path}': {e}")
    plt.close(fig)


def generate_single_experiment_analysis(history_file_path, output_folder_for_this_experiment, experiment_name):
    """
    Orchestrates parsing, transition analysis, and plotting for a single experiment history file.
    """
    print(f"\nProcessing History File: {history_file_path}")
    # Esta função já deve retornar os dados com as chaves RIR, AMS, TCS
    parsed_chunks = parse_rules_history_to_asts(history_file_path)

    if not parsed_chunks or len(parsed_chunks) < 2:
        print(f"  Not enough chunks in '{history_file_path}' to perform transition analysis.")
        return

    chunk_indices = sorted(parsed_chunks.keys())
    all_transition_data = []

    for i in range(len(chunk_indices) - 1):
        idx_i = chunk_indices[i]
        idx_j = chunk_indices[i+1]
        
        chunk_i_data = parsed_chunks[idx_i]
        chunk_j_data = parsed_chunks[idx_j]
        
        # A função analyze_chunk_transition deve ser atualizada para usar e retornar
        # RIR, AMS, TCS nos seus resultados.
        transition_summary, _ = analyze_chunk_transition(
            chunk_i_data, chunk_j_data,
            levenshtein_similarity_threshold=LEVENSHTEIN_SIMILARITY_PRE_FILTER_CONFIG,
            sm_threshold_for_modified=SM_THRESHOLD_MODIFIED_CONFIG
        )
       # print(f"DEBUG: transition_summary from analyze_chunk_transition for {idx_i}->{idx_j}: {transition_summary}")
        total_quants_j = { "and_count": 0, "or_count": 0, "atomic_condition_count": 0, "threshold_values": []}
        if 'rules_asts' in chunk_j_data:
            for class_label, ast_list in chunk_j_data['rules_asts'].items():
                for ast_rule in ast_list:
                    quants = collect_ast_quantitatives(ast_rule)
                    total_quants_j["and_count"] += quants["and_count"]
                    total_quants_j["or_count"] += quants["or_count"]
                    total_quants_j["atomic_condition_count"] += quants["atomic_condition_count"]
                    total_quants_j["threshold_values"].extend(quants["threshold_values"])
        
        avg_threshold = None
        if total_quants_j['threshold_values']:
            avg_threshold = sum(total_quants_j['threshold_values']) / len(total_quants_j['threshold_values'])
        
        # Usando as novas siglas para as chaves do dicionário
        data_for_graph_row = {
            "transition": f"{idx_i}→{idx_j}", # Usando seta para melhor visualização
            "TCS": transition_summary.get("STT", 0.0),  # Usar .get com default para segurança
            "RIR": transition_summary.get("MI", 0.0),
            "AMS": transition_summary.get("SMM", 0.0),
            "unchanged": transition_summary.get("unchanged_count", 0),
            "modified": transition_summary.get("modified_count", 0),
            "new": transition_summary.get("new_count", 0),
            "deleted": transition_summary.get("deleted_count", 0),
            "total_rules_j": transition_summary.get("total_rules_j", 0),
            "ands_j": total_quants_j["and_count"],
            "ors_j": total_quants_j["or_count"],
            "atomics_j": total_quants_j["atomic_condition_count"],
            "avg_thresh_j": avg_threshold
        }
        all_transition_data.append(data_for_graph_row)

    if all_transition_data:
        df_transitions = pd.DataFrame(all_transition_data)
        # print(f"\n  Transition Data for {experiment_name}:")
        # print(df_transitions.to_string())
        
        output_image_file = os.path.join(output_folder_for_this_experiment, f"{experiment_name}_evolution_plot.png")
        # if experiment_name == "STAGGER_f1f2f3f2_Abrupt":
        #     print(f"\nDEBUG: DataFrame for STAGGER_f1f2f3f2_Abrupt before plotting:")
        #     print(df_transitions.to_string())        
        plot_evolution_data(df_transitions, output_image_file, experiment_name)
    else:
        print(f"  No transition data generated for {experiment_name}.")


# --- Main Orchestration Logic ---
def main(root_path_config): # Adicionado root_path_config como parâmetro
    print(f"Starting analysis in root directory: {root_path_config}")

    main_output_abs_path = os.path.join(root_path_config, MAIN_OUTPUT_FOLDER_NAME)
    if not os.path.exists(main_output_abs_path):
        os.makedirs(main_output_abs_path)
        print(f"Main output folder created: {main_output_abs_path}")

    experiment_folders = find_experiment_folders(root_path_config)

    if not experiment_folders:
        print(f"No valid experiment folders found in '{root_path_config}'.")
        print("Ensure subfolders start with an uppercase letter, contain '_', and are not output folders.")
        return

    print(f"Found {len(experiment_folders)} potential experiment folder(s).")

    # Define quantas pastas processar (para teste ou completo)
    # num_folders_to_process = 2 # Para teste
    num_folders_to_process = len(experiment_folders) # Para processar todas

    folders_to_process = experiment_folders[:num_folders_to_process]
    if num_folders_to_process < len(experiment_folders) :
         print(f"\n--- INITIATING TEST RUN: Processing first {len(folders_to_process)} experiment folder(s) ---")


    for exp_folder_path in folders_to_process:
        experiment_name = os.path.basename(exp_folder_path)
        print(f"\n>>> Processing Experiment: {experiment_name} <<<")

        history_file = find_history_file(exp_folder_path)

        if history_file:
            specific_exp_output_folder = os.path.join(main_output_abs_path, experiment_name)
            # A pasta será criada por plot_evolution_data ao salvar
            
            generate_single_experiment_analysis(history_file, specific_exp_output_folder, experiment_name)
        else:
            print(f"  No RulesHistory_*.txt file found for experiment: {experiment_name} in {os.path.join(exp_folder_path, RUN_FOLDER_NAME)}")

    print("\n--- Orchestration Complete ---")

if __name__ == "__main__":
    sns.set_theme(style="whitegrid")
    
    # Limiares para a função analyze_chunk_transition
    LEVENSHTEIN_SIMILARITY_PRE_FILTER_CONFIG = 0.5  # Similaridade Levenshtein mínima para ser candidato (0.0 a 1.0)
    SM_THRESHOLD_MODIFIED_CONFIG = 0.8           # Severidade detalhada (SM) MÁXIMA para ser considerado modificado (0.0 a 1.0)
                                                 # SM < threshold -> é modificada
    # ---------------------------------    
    # --- DEFINA ESTE CAMINHO ---
    # O diretório que contém as pastas de experimento (ex: AGRAWAL_f1f3f4f7f10_Abrupt)
    user_root_path = r"G:\Outros computadores\Meu laptop\Downloads\DSL-AG\debug_standard_experiment_results"
    # ---------------------------------

    if not os.path.isdir(user_root_path):
        print(f"CRITICAL ERROR: Root directory '{user_root_path}' does not exist.")
        print("Please configure the 'user_root_path' variable correctly in the script.")
    else:
        main(user_root_path)