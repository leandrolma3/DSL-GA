---
# Configuration for the Genetic Algorithm Rule Learning Experiment

# --- Experiment Setup ---
experiment_settings:
  run_mode: 'drift_simulation'  # MODIFICADO: 'standard' → 'drift_simulation'
  standard_experiments:
    #- Electricity
    #- Shuttle
    - CovType
    - PokerHand
  drift_simulation_experiments:
    - RBF_Abrupt_Severe  # Stream para testar drift detection
    #- IntelLabSensors
    #- SEA_Stationary
    #- AGRAWAL_Stationary
    #- RBF_Stationary
    #- LED_Stationary
    #- HYPERPLANE_Stationary
    #- RANDOMTREE_Stationary
    #- STAGGER_Stationary
    #- WAVEFORM_Stationary
    #- SINE_Stationary
    #- AssetNegotiation_F2
    #- AssetNegotiation_F3
    #- AssetNegotiation_F4

  num_runs: 1   # Número de execuções independentes por dataset
  base_results_dir: "/content/drive/MyDrive/DSL-AG-hybrid/experiments" # MODIFICADO: Salvar no Google Drive
  logging_level: "INFO"    # Niveis: DEBUG, INFO, WARNING, ERROR, CRITICAL
  evaluation_period: 6000

# --- Data Handling ---
data_params:
  chunk_size: 6000
  num_chunks: 8  # MODIFICADO: 6→8 para testar seeding 85% após drift SEVERE (chunks 5-7)
  # max_instances: Calcule dinamicamente ou defina um limite alto
  max_instances: 54000  # 6000 * 9 = 54000 (8 chunks + 1 buffer)

# --- Genetic Algorithm Parameters ---
ga_params:
  population_size: 120  # Experimento com HC Inteligente - população grande
  max_generations: 200  # Máximo 200 gens (early stopping deve parar em ~30-50)
  max_generations_recovery: 25  # REDUZIDO
  recovery_generation_multiplier: 1.5
  enable_explicit_drift_adaptation: true # Master switch for these adaptations
    # Mutation override during recovery
  recovery_mutation_override_rate: 0.5 # Taxa de mutação mais alta (ex: 0.3 a 0.8)
  recovery_mutation_override_generations: 10 # Por quantas gerações aplicar o override (0 para o chunk inteiro)
  # Population reset/diversification during recovery
  recovery_initialization_strategy: "full_random" # Opções: "default", "diversify" (mais aleatórios/mutantes agressivos)
  recovery_random_individual_ratio: 0.6 # Percentual de indivíduos aleatórios na estratégia "diversify" (ex: 60%)

  # Complexity adjustment during recovery
  recovery_max_depth_multiplier: 1.5 # Aumenta a profundidade máxima em 20%
  recovery_max_rules_multiplier: 1.5
  elitism_rate: 0.1
  intelligent_mutation_rate: 0.8
  initial_tournament_size: 2
  final_tournament_size: 5  # Limite superior para tamanho dinâmico do torneio
  max_rules_per_class: 15
  initial_max_depth: 10  # Profundidade inicial/máxima das árvores de regras
  # Taxa de mutação é dinâmica (calculada em ga.py), mas pode ter parâmetros base aqui se necessário
  stagnation_threshold: 10  # Threshold para ativar Hill Climbing (ex: 10 gerações sem melhora)
  early_stopping_patience: 20  # Layer 3 (fallback): Parada após X gerações sem melhora
  # EARLY STOPPING ADAPTATIVO (3 CAMADAS) - Implementado em ga.py:
  # - Layer 1: Para em ~15 gens se G-mean ≥ 88% (elite satisfatório)
  # - Layer 2: Para em ~30-40 gens se melhoria < 0.5% nas últimas 30 gens
  # - Layer 3: Para após 'early_stopping_patience' gens (fallback tradicional)
  # Economia estimada: 70-80% do tempo vs configuração anterior

  # --- Hill Climbing Adaptativo (LEGADO - Manter false se usar hierárquico) ---
  hc_enable_adaptive: false  # Sistema legado de threshold simples (desabilitado)
  hc_gmean_threshold: 0.90   # Threshold legado (não usado quando hierárquico ativo)

  # --- Hill Climbing Hierárquico v2.0 (RECOMENDADO) ---
  hc_hierarchical_enabled: true  # Habilita sistema hierárquico multi-nível
  # Níveis automáticos baseado em G-mean do elite:
  # - AGGRESSIVE (70-85%): Exploração agressiva, grandes mudanças estruturais
  # - MODERATE (85-92%):   Refinamento moderado, ajustes estruturais
  # - FINE_TUNING (92-98%): Fine-tuning, ajustes finos de precisão
  # - Desabilita se elite >= 98% (quase perfeito)

  # --- Seeding Configuration ---
  enable_dt_seeding_on_init: true       # Habilita/desabilita esta funcionalidade
  dt_seeding_ratio_on_init: 0.8         # 80% seeding FORTE (para testar HC adaptativo quando elite >90%)
  dt_seeding_depths_on_init: [4, 7, 10, 13]  # DTs profundas (elite esperado ~95-99%)
  dt_seeding_sample_size_on_init: 2000  # Sample grande
  dt_seeding_rules_to_replace_per_class: 4 # Muitas regras por classe

  # --- Seeding Probabilístico (Fase 2) ---
  dt_rule_injection_ratio: 0.5          # Fração de regras DT a injetar (1.0 = 100%, 0.5 = 50%) - TESTE: 50%

  # --- Seeding Adaptativo (Fase 3) ---
  enable_adaptive_seeding: true         # Habilita seeding adaptativo (sobrescreve params fixos acima)
  adaptive_seeding_strategy: 'dt_probe' # Estratégia de estimativa: 'dt_probe' (usa DT rasa como proxy)
  # Thresholds para classificação de complexidade (apenas para strategy='dt_probe')
  adaptive_complexity_simple_threshold: 0.90   # DT probe acc >= 0.90 → problema SIMPLES
  adaptive_complexity_medium_threshold: 0.75   # DT probe acc >= 0.75 → problema MÉDIO (< 0.75 → COMPLEXO)

  # --- Crossover Balanceado Inteligente ---
  use_balanced_crossover: true          # Habilita crossover balanceado (70% qualidade + 30% diversidade)
  # Ratios adaptativos por fase evolutiva (configurados automaticamente em ga_operators.py):
  # - Fase Exploração (Gen 1-20):  50% qualidade + 50% diversidade
  # - Fase Balanceada (Gen 21-60): 70% qualidade + 30% diversidade
  # - Fase Refinamento (Gen 61+):  85% qualidade + 15% diversidade


# --- Memory Management ---
memory_params:
  max_memory_size: 20  # Máximo de indivíduos no buffer best_ever_memory
  enable_active_memory_pruning: true # ou false
  memory_max_age_chunks: 10 # Ex: Indivíduos mais velhos que 10 chunks são candidatos a remoção
  # Percentil de fitness abaixo do qual um indivíduo velho pode ser removido (ex: 0.25 = remover se estiver nos 25% piores da memória)
  memory_fitness_threshold_percentile_for_old_removal: 0.25 
  # Mínimo de indivíduos a manter na memória durante a limpeza ativa, para não esvaziá-la demais
  memory_min_retain_count_during_pruning: 5 
  abandon_memory_on_severe_performance_drop: true
  performance_drop_threshold_for_memory_abandon: 0.55 # AUMENTADO: 0.1→0.55 para detectar RBF chunk 4 (46%)
  consecutive_bad_chunks_for_memory_abandon: 1  # REDUZIDO: 2→1 para reagir mais rápido a drift abrupto
  historical_reference_size: 500

# --- Fitness Function Parameters ---
fitness_params:
  class_coverage_coefficient: 0.2
  gmean_bonus_coefficient: 0.1
  # Coeficientes de penalidade - AJUSTE ESTES VALORES CUIDADOSAMENTE
  initial_regularization_coefficient: 0.001  # Penalidade por complexidade (nós+profundidade)
  feature_penalty_coefficient: 0.1       # Penalidade pelo número de features usadas
  operator_penalty_coefficient: 0.0001    # Penalidade pela diversidade interna de operadores
  threshold_penalty_coefficient: 0.0001   # Penalidade pela diversidade interna de thresholds
  operator_change_coefficient: 0.05    # Penalidade por mudança de operadores vs chunk anterior
  gamma: 0.1                           # Penalidade por *aumento* no nº de features vs chunk anterior
  drift_penalty_reduction_threshold: 0.1
  absolute_bad_threshold_for_label: 0.60  # AUMENTADO: 0.35→0.60 para detectar performance ruim mais cedo
  # Limites para ajuste futuro de parâmetros inter-chunk (se reativado)
  min_regularization_coeff: 0.01
  max_regularization_coeff: 0.3

  # beta (penalidade por desvio da memória) é calculado dinamicamente em ga.py/fitness.py

parallelism:
  enabled: true   # Mude para false para testar sem paralelismo
  num_workers: null  # null = auto (os.cpu_count()), ou um número exato (ex: 4, 8)

# ===================================================================
# Drift Analysis Configuration
# This section defines the properties of generator families and their concepts.
# It is read by analyze_concept_difference.py to calculate drift severity.
# ===================================================================
drift_analysis:
  severity_samples: 20000
  heatmap_save_directory: "test_real_results_heatmaps/concept_heatmapsS"

  # --- Generator Family Definitions ---
  datasets:
    # --- ADICIONADO: Definições para Datasets Reais ---
    ELECTRICITY:
      class: 'river.datasets.Elec2'
      
    SHUTTLE:
      loader: 'local_csv'
      source_path: 'datasets/processed/shuttle_processed.csv'
      target_column: 'class'

    COVERTYPE:
      loader: 'local_csv'
      source_path: 'datasets/processed/covertype_processed.csv'
      target_column: 'class'

    POKER:
      loader: 'local_csv'
      source_path: 'datasets/processed/poker_processed.csv'
      target_column: 'class'
      
    INTELLABSENSORS:
      loader: 'local_csv'
      source_path: 'datasets/processed/intellabsensors_processed.csv'
      target_column: 'class'

    SEA:
      class: 'river.datasets.synth.SEA'
      n_features: 3
      feature_bounds: [[0, 10], [0, 10], [0, 10]]
      concepts:
        'f1': {variant: 0} # In river, SEA(classification_function=0) has threshold ~8
        'f2': {variant: 1} # threshold ~9
        'f3': {variant: 2} # threshold ~7
        'f4': {variant: 3} # threshold ~9.5
      pairs_to_compare:
        - ['f1', 'f2']
        - ['f1', 'f3']
        - ['f1', 'f4']
        - ['f2', 'f3']
        - ['f2', 'f4']
        - ['f3', 'f4']

    AGRAWAL:
      class: 'river.datasets.synth.Agrawal'
      n_features: 9
      feature_bounds: [[0, 1]]
      concepts:
        'f1': {classification_function: 1}
        'f2': {classification_function: 2}
        'f3': {classification_function: 3}
        'f4': {classification_function: 4}
        'f5': {classification_function: 5}
        'f6': {classification_function: 6}
        'f7': {classification_function: 7}
        'f8': {classification_function: 8}
        'f9': {classification_function: 9}
        'f10': {classification_function: 10}
      pairs_to_compare:
        - ['f1', 'f2']
        - ['f1', 'f3']
        - ['f1', 'f6']
        - ['f2', 'f7']
        - ['f5', 'f9']

    RBF:
      class: 'river.datasets.synth.RandomRBF'
      n_features: 10
      feature_bounds: [[0, 1]]
      concepts:
        'c1': {seed_model: 42}
        'c2_severe': {seed_model: 84}
        'c3_moderate': {seed_model: 60}
      pairs_to_compare:
        - ['c1', 'c2_severe']
        - ['c1', 'c3_moderate']
        - ['c2_severe', 'c3_moderate']

    STAGGER:
      class: 'river.datasets.synth.STAGGER'
      n_features: 3
      feature_bounds: [[1, 3], [1, 3], [1, 3]]
      concepts:
        'f1': {classification_function: 0}
        'f2': {classification_function: 1}
        'f3': {classification_function: 2}
      pairs_to_compare:
        - ['f1', 'f2']
        - ['f1', 'f3']
        - ['f2', 'f3']

    LED:
      class: 'river.datasets.synth.LED'
      n_features: 24
      feature_bounds: [[0, 1]]
      concepts:
        'c1_no_noise': { noise_percentage: 0, seed: 42 }
        'c2_with_noise': { noise_percentage: 0.1, seed: 42}
      pairs_to_compare:
        - ['c1_no_noise', 'c2_with_noise']

    HYPERPLANE:
      class: 'river.datasets.synth.Hyperplane'
      n_features: 10
      n_classes: 4
      feature_bounds: [[0, 1]]
      concepts:
        'plane1': { seed: 42 }
        'plane2': { seed: 84, mag_change: 0.01 }
      pairs_to_compare:
        - ['plane1', 'plane2']

    RANDOMTREE:
      class: 'river.datasets.synth.RandomTree'
      n_features: 10
      n_classes: 2
      feature_bounds: [[0, 1]]
      concepts:
        'tree1': { seed_tree: 42, seed_sample: 42 }
        'tree2': { seed_tree: 84, seed_sample: 84 }
      pairs_to_compare:
        - ['tree1', 'tree2']

    WAVEFORM:
      class: 'river.datasets.synth.Waveform'
      n_features: 40
      feature_bounds: [[0, 6]]
      concepts:
        'wave1': { has_noise: false }
        'wave2': { has_noise: true }
      pairs_to_compare:
        - ['wave1', 'wave2']
    
    SINE:
      class: 'river.datasets.synth.Sine'
      n_features: 5 
      feature_bounds:
        - [0, 6.28]
        - [0, 6.28]
        - [0, 6.28]
        - [0, 6.28]
        - [0, 6.28]
      concepts:
        # ADICIONADO: Parâmetros para diferenciar os conceitos
        'f1_sum': {type: 'sum', threshold: 1.0}
        'f2_prod': {type: 'prod', threshold: 0.3}
        'f3_sum_alt': {type: 'sum', threshold: 1.5}
      pairs_to_compare:
        - ['f1_sum', 'f2_prod']
        - ['f1_sum', 'f3_sum_alt']
        - ['f2_prod', 'f3_sum_alt']

    # --- ADICIONADO: Definição para a família AssetNegotiation ---
    ASSETNEGOTIATION:
      # NOTA: Este gerador não é padrão. Usando Agrawal como base funcional
      # com 5 atributos numéricos para simular o comportamento.
      class: 'custom_generators.AssetNegotiation'
      params: { seed: 42 }
      concepts:
        'F2': { classification_function: 1 } # Mapeando F2 para a função 2 do gerador
        'F3': { classification_function: 2 } # Mapeando F3 para a função 3
        'F4': { classification_function: 3 } # Mapeando F4 para a função 4
      pairs_to_compare:
        - ['F2', 'F3']
        - ['F2', 'F4']
        - ['F3', 'F4']

# ===================================================================
# Experimental Stream Definitions
# Defines over 40 varied scenarios for the data_handling.py script.
# NOTE: The 'run_mode' is now assumed to be set globally in 'experiment_settings'.
# ===================================================================
experimental_streams:
  # --- ADICIONADO: Streams de Datasets Reais ---
  Electricity: { dataset_type: 'ELECTRICITY' }
  Shuttle: { dataset_type: 'SHUTTLE' }
  CovType: { dataset_type: 'COVERTYPE' }
  PokerHand: { dataset_type: 'POKER' }
  IntelLabSensors: { dataset_type: 'INTELLABSENSORS' }
  # --- Geração Estacionária (Sem Drift Explícito) ---
  # O novo data_handling.py irá gerar estes como um fluxo contínuo
  # do gerador base, sem `concept_sequence`.
  SEA_Stationary: { dataset_type: 'SEA' }
  AGRAWAL_Stationary: { dataset_type: 'AGRAWAL' }
  RBF_Stationary: { dataset_type: 'RBF', params_override: {n_features: 50, n_classes: 4} }
  LED_Stationary: { dataset_type: 'LED' }
  HYPERPLANE_Stationary: { dataset_type: 'HYPERPLANE' }
  RANDOMTREE_Stationary: { dataset_type: 'RANDOMTREE' }
  STAGGER_Stationary: { dataset_type: 'STAGGER' }
  WAVEFORM_Stationary: { dataset_type: 'WAVEFORM' }
  SINE_Stationary: { dataset_type: 'SINE' }
  AssetNegotiation_F2: { dataset_type: 'ASSETNEGOTIATION', params_override: {classification_function: 1} }
  AssetNegotiation_F3: { dataset_type: 'ASSETNEGOTIATION', params_override: {classification_function: 2} }
  AssetNegotiation_F4: { dataset_type: 'ASSETNEGOTIATION', params_override: {classification_function: 3} }


  # --- New varied drift scenarios ---
  SINE_Abrupt_Simple:
    dataset_type: 'SINE'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    concept_sequence:
      - { concept_id: 'f1_sum', duration_chunks: 6 }
      - { concept_id: 'f2_prod', duration_chunks: 6 }

  SINE_Gradual_Recurring:
    dataset_type: 'SINE'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 2
    concept_sequence:
      - { concept_id: 'f1_sum', duration_chunks: 4 }
      - { concept_id: 'f3_sum_alt', duration_chunks: 5 }
      - { concept_id: 'f1_sum', duration_chunks: 4 }

  SINE_Abrupt_Recurring_Noise:
    dataset_type: 'SINE'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    noise_config: { enabled: true, attribute_ratio: 0.45, noise_level: 0.1 }
    concept_sequence:
      - { concept_id: 'f1_sum', duration_chunks: 4 }
      - { concept_id: 'f2_prod', duration_chunks: 5 }
      - { concept_id: 'f1_sum', duration_chunks: 4 }

  SEA_Abrupt_Simple:
    dataset_type: 'SEA'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 5 }
      - { concept_id: 'f3', duration_chunks: 5 }
  SEA_Abrupt_Chain:
    dataset_type: 'SEA'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 3 }
      - { concept_id: 'f2', duration_chunks: 3 }
      - { concept_id: 'f4', duration_chunks: 3 }
  AGRAWAL_Abrupt_Simple_Mild:
    dataset_type: 'AGRAWAL'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 5 }
      - { concept_id: 'f2', duration_chunks: 5 }
  AGRAWAL_Abrupt_Simple_Severe:
    dataset_type: 'AGRAWAL'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 5 }
      - { concept_id: 'f6', duration_chunks: 5 }
  RBF_Abrupt_Severe:
    dataset_type: 'RBF'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    concept_sequence:
      - { concept_id: 'c1', duration_chunks: 5 }
      - { concept_id: 'c2_severe', duration_chunks: 5 }
  STAGGER_Abrupt_Chain:
    dataset_type: 'STAGGER'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 4 }
      - { concept_id: 'f2', duration_chunks: 4 }
      - { concept_id: 'f3', duration_chunks: 4 }
  HYPERPLANE_Abrupt_Simple:
    dataset_type: 'HYPERPLANE'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    concept_sequence:
      - { concept_id: 'plane1', duration_chunks: 6 }
      - { concept_id: 'plane2', duration_chunks: 6 }

  # --- Category 2: Gradual Drifts ---
  SEA_Gradual_Simple_Fast:
    dataset_type: 'SEA'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 1
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 5 }
      - { concept_id: 'f3', duration_chunks: 5 }
  SEA_Gradual_Simple_Slow:
    dataset_type: 'SEA'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 3
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 6 }
      - { concept_id: 'f3', duration_chunks: 6 }
  AGRAWAL_Gradual_Chain:
    dataset_type: 'AGRAWAL'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 2
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 3 }
      - { concept_id: 'f3', duration_chunks: 3 }
      - { concept_id: 'f5', duration_chunks: 3 }
      - { concept_id: 'f7', duration_chunks: 3 }
  RBF_Gradual_Moderate:
    dataset_type: 'RBF'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 2
    concept_sequence:
      - { concept_id: 'c1', duration_chunks: 5 }
      - { concept_id: 'c3_moderate', duration_chunks: 5 }
  RANDOMTREE_Gradual_Simple:
    dataset_type: 'RANDOMTREE'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 2
    concept_sequence:
      - { concept_id: 'tree1', duration_chunks: 5 }
      - { concept_id: 'tree2', duration_chunks: 5 }
  WAVEFORM_Gradual_Simple:
    dataset_type: 'WAVEFORM'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 2
    concept_sequence:
      - { concept_id: 'wave1', duration_chunks: 5 }
      - { concept_id: 'wave2', duration_chunks: 5 }
  LED_Gradual_Simple:
    dataset_type: 'LED'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 2
    concept_sequence:
      - { concept_id: 'c1_no_noise', duration_chunks: 5 }
      - { concept_id: 'c2_with_noise', duration_chunks: 5 }

  # --- Category 3: Recurring, Blips, and Mixed Drifts ---
  SEA_Abrupt_Recurring:
    dataset_type: 'SEA'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 4 }
      - { concept_id: 'f3', duration_chunks: 5 }
      - { concept_id: 'f1', duration_chunks: 4 }
  AGRAWAL_Gradual_Recurring:
    dataset_type: 'AGRAWAL'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 2
    concept_sequence:
      - { concept_id: 'f2', duration_chunks: 4 }
      - { concept_id: 'f7', duration_chunks: 5 }
      - { concept_id: 'f2', duration_chunks: 4 }
  RBF_Abrupt_Blip:
    dataset_type: 'RBF'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    concept_sequence:
      - { concept_id: 'c1', duration_chunks: 6 }
      - { concept_id: 'c3_moderate', duration_chunks: 1 } # Short blip
      - { concept_id: 'c1', duration_chunks: 6 }
  STAGGER_Mixed_Recurring: # Abrupt and Gradual drifts
    dataset_type: 'STAGGER'
    drift_type: 'abrupt' # Base type for non-specified transitions
    gradual_drift_width_chunks: 2 # Only used if transition overrides drift_type
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 3 }
      - { concept_id: 'f2', duration_chunks: 3, drift_type_override: 'gradual' } # Gradual transition f1->f2
      - { concept_id: 'f3', duration_chunks: 3 } # Abrupt transition f2->f3
      - { concept_id: 'f1', duration_chunks: 3 } # Abrupt recurrence f3->f1
  RBF_Severe_Gradual_Recurrent:
    dataset_type: 'RBF'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 2
    concept_sequence:
      - { concept_id: 'c1', duration_chunks: 3 }
      - { concept_id: 'c2_severe', duration_chunks: 4 }
      - { concept_id: 'c1', duration_chunks: 3 }

  # --- Category 4: Drifts with Noise ---
  SEA_Abrupt_Chain_Noise:
    dataset_type: 'SEA'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    noise_config: { enabled: true, attribute_ratio: 0.45, noise_level: 0.1 }
    concept_sequence:
      - { concept_id: 'f1', duration_chunks: 3 }
      - { concept_id: 'f2', duration_chunks: 3 }
      - { concept_id: 'f4', duration_chunks: 3 }
  AGRAWAL_Gradual_Recurring_Noise:
    dataset_type: 'AGRAWAL'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 2
    noise_config: { enabled: true, attribute_ratio: 0.45, noise_level: 0.1 }
    concept_sequence:
      - { concept_id: 'f2', duration_chunks: 4 }
      - { concept_id: 'f7', duration_chunks: 5 }
      - { concept_id: 'f2', duration_chunks: 4 }
  RBF_Abrupt_Blip_Noise:
    dataset_type: 'RBF'
    drift_type: 'abrupt'
    gradual_drift_width_chunks: 0
    noise_config: { enabled: true, attribute_ratio: 0.45, noise_level: 0.1 }
    concept_sequence:
      - { concept_id: 'c1', duration_chunks: 6 }
      - { concept_id: 'c3_moderate', duration_chunks: 1 }
      - { concept_id: 'c1', duration_chunks: 6 }
  HYPERPLANE_Gradual_Noise:
    dataset_type: 'HYPERPLANE'
    drift_type: 'gradual'
    gradual_drift_width_chunks: 3
    noise_config: { enabled: true, attribute_ratio: 0.45, noise_level: 0.1 }
    concept_sequence:
      - { concept_id: 'plane1', duration_chunks: 6 }
      - { concept_id: 'plane2', duration_chunks: 6 }

  # --- Category 5: More variations to reach 40+ streams ---
  # Abrupt
  AGRAWAL_Abrupt_Chain_Long: { dataset_type: 'AGRAWAL', drift_type: 'abrupt', gradual_drift_width_chunks: 0, concept_sequence: [{concept_id: 'f1', duration_chunks: 2},{concept_id: 'f2', duration_chunks: 2},{concept_id: 'f3', duration_chunks: 2},{concept_id: 'f4', duration_chunks: 2},{concept_id: 'f5', duration_chunks: 2}] }
  RANDOMTREE_Abrupt_Simple: { dataset_type: 'RANDOMTREE', drift_type: 'abrupt', gradual_drift_width_chunks: 0, concept_sequence: [{concept_id: 'tree1', duration_chunks: 5},{concept_id: 'tree2', duration_chunks: 5}] }
  LED_Abrupt_Simple: { dataset_type: 'LED', drift_type: 'abrupt', gradual_drift_width_chunks: 0, concept_sequence: [{concept_id: 'c1_no_noise', duration_chunks: 5},{concept_id: 'c2_with_noise', duration_chunks: 5}] }
  WAVEFORM_Abrupt_Simple: { dataset_type: 'WAVEFORM', drift_type: 'abrupt', gradual_drift_width_chunks: 0, concept_sequence: [{concept_id: 'wave1', duration_chunks: 5},{concept_id: 'wave2', duration_chunks: 5}] }
  # Gradual
  STAGGER_Gradual_Chain: { dataset_type: 'STAGGER', drift_type: 'gradual', gradual_drift_width_chunks: 2, concept_sequence: [{concept_id: 'f1', duration_chunks: 4},{concept_id: 'f2', duration_chunks: 4},{concept_id: 'f3', duration_chunks: 4}] }
  HYPERPLANE_Gradual_Simple: { dataset_type: 'HYPERPLANE', drift_type: 'gradual', gradual_drift_width_chunks: 3, concept_sequence: [{concept_id: 'plane1', duration_chunks: 6},{concept_id: 'plane2', duration_chunks: 6}] }
  RBF_Gradual_Severe: { dataset_type: 'RBF', drift_type: 'gradual', gradual_drift_width_chunks: 2, concept_sequence: [{concept_id: 'c1', duration_chunks: 5},{concept_id: 'c2_severe', duration_chunks: 5}] }
  AGRAWAL_Gradual_Mild_to_Severe: { dataset_type: 'AGRAWAL', drift_type: 'gradual', gradual_drift_width_chunks: 2, concept_sequence: [{concept_id: 'f1', duration_chunks: 4},{concept_id: 'f2', duration_chunks: 4},{concept_id: 'f6', duration_chunks: 4}] }
  # Recurring & Blips
  STAGGER_Abrupt_Recurring: { dataset_type: 'STAGGER', drift_type: 'abrupt', gradual_drift_width_chunks: 0, concept_sequence: [{concept_id: 'f1', duration_chunks: 4},{concept_id: 'f3', duration_chunks: 5},{concept_id: 'f1', duration_chunks: 4}] }
  SEA_Gradual_Recurring: { dataset_type: 'SEA', drift_type: 'gradual', gradual_drift_width_chunks: 2, concept_sequence: [{concept_id: 'f1', duration_chunks: 4},{concept_id: 'f4', duration_chunks: 5},{concept_id: 'f1', duration_chunks: 4}] }
  AGRAWAL_Gradual_Blip: { dataset_type: 'AGRAWAL', drift_type: 'gradual', gradual_drift_width_chunks: 1, concept_sequence: [{concept_id: 'f1', duration_chunks: 6},{concept_id: 'f9', duration_chunks: 1},{concept_id: 'f1', duration_chunks: 6}] }
  RANDOMTREE_Abrupt_Recurring: { dataset_type: 'RANDOMTREE', drift_type: 'abrupt', gradual_drift_width_chunks: 0, concept_sequence: [{concept_id: 'tree1', duration_chunks: 4},{concept_id: 'tree2', duration_chunks: 5},{concept_id: 'tree1', duration_chunks: 4}] }
  # With Noise
  STAGGER_Abrupt_Chain_Noise: { dataset_type: 'STAGGER', drift_type: 'abrupt', gradual_drift_width_chunks: 0, noise_config: {enabled: true, attribute_ratio: 0.45, noise_level: 0.1}, concept_sequence: [{concept_id: 'f1', duration_chunks: 4},{concept_id: 'f2', duration_chunks: 4},{concept_id: 'f3', duration_chunks: 4}] }
  RBF_Gradual_Severe_Noise: { dataset_type: 'RBF', drift_type: 'gradual', gradual_drift_width_chunks: 2, noise_config: {enabled: true, attribute_ratio: 0.45, noise_level: 0.1}, concept_sequence: [{concept_id: 'c1', duration_chunks: 5},{concept_id: 'c2_severe', duration_chunks: 5}] }
  RANDOMTREE_Gradual_Noise: { dataset_type: 'RANDOMTREE', drift_type: 'gradual', gradual_drift_width_chunks: 2, noise_config: {enabled: true, attribute_ratio: 0.45, noise_level: 0.1}, concept_sequence: [{concept_id: 'tree1', duration_chunks: 5},{concept_id: 'tree2', duration_chunks: 5}] }
  AGRAWAL_Abrupt_Simple_Severe_Noise: { dataset_type: 'AGRAWAL', drift_type: 'abrupt', gradual_drift_width_chunks: 0, noise_config: {enabled: true, attribute_ratio: 0.45, noise_level: 0.1}, concept_sequence: [{concept_id: 'f1', duration_chunks: 5},{concept_id: 'f6', duration_chunks: 5}] }
  
  # Duplicates of Bartosz paper streams for clarity
  Bartosz_RandomTree_drift: { dataset_type: 'RANDOMTREE', drift_type: 'gradual', gradual_drift_width_chunks: 2, concept_sequence: [{concept_id: 'tree1', duration_chunks: 5},{concept_id: 'tree2', duration_chunks: 5}] }
  Bartosz_Agrawal_recurring_drift: { dataset_type: 'AGRAWAL', drift_type: 'abrupt', gradual_drift_width_chunks: 0, concept_sequence: [{concept_id: 'f1', duration_chunks: 3},{concept_id: 'f6', duration_chunks: 4},{concept_id: 'f1', duration_chunks: 3}] }
  Bartosz_SEA_drift_noise: { dataset_type: 'SEA', drift_type: 'abrupt', gradual_drift_width_chunks: 0, noise_config: { enabled: true, attribute_ratio: 0.45, noise_level: 0.1 }, concept_sequence: [{concept_id: 'f1', duration_chunks: 2},{concept_id: 'f2', duration_chunks: 2},{concept_id: 'f3', duration_chunks: 2},{concept_id: 'f4', duration_chunks: 2}] }